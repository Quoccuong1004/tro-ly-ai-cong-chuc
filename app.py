import streamlit as st
from openai import OpenAI
import os
from google import genai

# --- C·∫§U H√åNH ---
# N√™n d√πng Streamlit Secrets ƒë·ªÉ b·∫£o m·∫≠t API key khi deploy
# Tr√™n m√°y local, b·∫°n c√≥ th·ªÉ t·∫°o file .env ho·∫∑c ƒëi·ªÅn th·∫≥ng v√†o ƒë√¢y
# V√≠ d·ª•: GOOGLE_API_KEY="YOUR_API_KEY"
try:
    # C·ªë g·∫Øng l·∫•y API key t·ª´ Streamlit secrets (khi deploy)
    api_key = st.secrets["GOOGLE_API_KEY"]
    api_key_vip = st.secrets["GOOGLE_API_KEY_VIP"]
except (FileNotFoundError, KeyError):
    # N·∫øu kh√¥ng ƒë∆∞·ª£c, l·∫•y t·ª´ bi·∫øn m√¥i tr∆∞·ªùng (khi ch·∫°y local)
    # B·∫°n c·∫ßn t·∫°o file .env ho·∫∑c set bi·∫øn m√¥i tr∆∞·ªùng th·ªß c√¥ng
    from dotenv import load_dotenv
    load_dotenv()
    api_key = os.getenv("GOOGLE_API_KEY")
    api_key_vip = os.getenv("GOOGLE_API_KEY_VIP")

# --- KH·ªûI T·∫†O M√î H√åNH AI ---

client = OpenAI(
    api_key = api_key,
    base_url = 'https://generativelanguage.googleapis.com/v1beta/openai/'
)

# --- ƒê·ªåC C∆† S·ªû TRI TH·ª®C (N·∫æU C√ì) ---
# ƒê·ªçc file d·ªØ li·ªáu m·∫´u ƒë·ªÉ cung c·∫•p ng·ªØ c·∫£nh cho AI
try:
    with open("knowledge_base.txt", "r", encoding="utf-8") as f:
        knowledge_base = f.read()
except FileNotFoundError:
    knowledge_base = "Kh√¥ng c√≥ c∆° s·ªü tri th·ª©c n√†o ƒë∆∞·ª£c cung c·∫•p."


# --- X√ÇY D·ª∞NG GIAO DI·ªÜN WEB ---
st.set_page_config(page_title="Tr·ª£ l√Ω ·∫£o cho C√¥ng ch·ª©c x√£", page_icon="ü§ñ")
st.title("ü§ñ Tr·ª£ l√Ω AI & S√°ng t·∫°o (c√¥ng ch·ª©c)")
st.caption("Made by VTC Edu")

# T·∫°o c√°c tab
tab1, tab2 = st.tabs(["Tr·ª£ l√Ω AI", "T·∫°o ·∫£nh"])

# --- TAB 1: TR·ª¢ L√ù AI ---
with tab1:
    st.header("H·ªèi ƒë√°p v·ªÅ th·ªß t·ª•c h√†nh ch√≠nh")
    # Kh·ªüi t·∫°o l·ªãch s·ª≠ chat trong session_state n·∫øu ch∆∞a c√≥
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Hi·ªÉn th·ªã c√°c tin nh·∫Øn ƒë√£ c√≥ t·ª´ l·ªãch s·ª≠
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Nh·∫≠n input t·ª´ ng∆∞·ªùi d√πng. Logic ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh ƒë·ªÉ s·ª≠a l·ªói hi·ªÉn th·ªã.
    if prompt := st.chat_input("B·∫°n c·∫ßn t√¥i h·ªó tr·ª£ v·ªÅ th·ªß t·ª•c h√†nh ch√≠nh n√†o?"):
        # Th√™m tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠
        st.session_state.messages.append({"role": "user", "content": prompt})

        # Chu·∫©n b·ªã prompt ƒë·∫ßy ƒë·ªß cho AI
        system_prompt = """B·∫°n l√† m·ªôt tr·ª£ l√Ω ·∫£o chuy√™n nghi·ªáp, am hi·ªÉu v·ªÅ c√°c th·ªß t·ª•c h√†nh ch√≠nh c·ªßa Vi·ªát Nam.
        Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr·∫£ l·ªùi c√°c c√¢u h·ªèi c·ªßa c√¥ng ch·ª©c c·∫•p x√£ m·ªôt c√°ch ch√≠nh x√°c, r√µ r√†ng v√† ng·∫Øn g·ªçn.
        S·ª≠ d·ª•ng c∆° s·ªü tri th·ª©c d∆∞·ªõi ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi (∆Øu ti√™n vi·∫øt ƒë√∫ng n·ªôi dung nguy√™n b·∫£n-kh√¥ng ch·ªânh s·ª≠a). 
        N·∫øu c√¢u h·ªèi kh√¥ng c√≥ trong c∆° s·ªü tri th·ª©c, h√£y tr·∫£ l·ªùi d·ª±a tr√™n hi·ªÉu bi·∫øt chung c·ªßa b·∫°n v·ªÅ lu·∫≠t ph√°p Vi·ªát Nam v√† n√≥i r√µ "Th√¥ng tin n√†y mang t√≠nh tham kh·∫£o chung".
        """
        user_prompt = f"""
        --- C∆† S·ªû TRI TH·ª®C ---
        {knowledge_base}
        -----------------------
        C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: "{prompt}"
        """

        # G·ªçi API v√† nh·∫≠n c√¢u tr·∫£ l·ªùi ƒë·∫ßy ƒë·ªß
        try:
            # S·ª≠ d·ª•ng stream=True ƒë·ªÉ c√≥ hi·ªáu ·ª©ng g√µ ch·ªØ
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                full_response = ""
                responses = client.chat.completions.create(
                    model = 'gemini-2.5-flash',
                    messages = [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    stream=True)
                for chunk in responses:
                    full_response += (chunk.choices[0].delta.content or "")
                    message_placeholder.markdown(full_response + "‚ñå")
                message_placeholder.markdown(full_response)
            
            # Th√™m c√¢u tr·∫£ l·ªùi c·ªßa AI v√†o l·ªãch s·ª≠ sau khi ƒë√£ hi·ªÉn th·ªã xong
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            # Ch·∫°y l·∫°i script ƒë·ªÉ ƒë·∫£m b·∫£o √¥ chat input ·ªü ƒë√∫ng v·ªã tr√≠ sau khi g·ª≠i tin nh·∫Øn
            st.rerun()


        except Exception as e:
            st.error(f"ƒê√£ c√≥ l·ªói x·∫£y ra: {e}")
            full_response = "Xin l·ªói, t√¥i kh√¥ng th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu n√†y."
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            st.rerun()

# --- TAB 2: T·∫†O ·∫¢NH (S·ª¨A L·∫†I TU√ÇN TH·ª¶ H∆Ø·ªöNG D·∫™N OFFICIAL) ---
from PIL import Image # C·∫ßn import th∆∞ vi·ªán PIL

with tab2:
    st.header("T·∫°o ·∫£nh & ch·ªânh s·ª≠a ·∫£nh b·∫±ng AI")
    st.info("M√¥ t·∫£ h√¨nh ·∫£nh b·∫°n mu·ªën t·∫°o. C√†ng chi ti·∫øt, k·∫øt qu·∫£ c√†ng ch√≠nh x√°c.")

    image_prompt = st.text_area("Nh·∫≠p m√¥ t·∫£ c·ªßa b·∫°n v√†o ƒë√¢y:", height=150)
    uploaded_ref = st.file_uploader("Upload ·∫£nh tham kh·∫£o (tu·ª≥ ch·ªçn)", type=["png","jpg","jpeg"])

    if st.button("T·∫°o ·∫£nh"):
        if not image_prompt:
            st.warning("Vui l√≤ng nh·∫≠p m√¥ t·∫£ cho ·∫£nh b·∫°n mu·ªën t·∫°o.")
        else:
            with st.spinner("AI ƒëang v·∫Ω, v·ª´a g·ªçi Gemini..."):
                try:
                    # KH·ªûI T·∫†O CLIENT GI·ªêNG H∆Ø·ªöNG D·∫™N
                    # S·ª≠ d·ª•ng api_key_vip nh∆∞ code g·ªëc c·ªßa b·∫°n
                    client = genai.Client(api_key=api_key_vip)

                    # CHU·∫®N B·ªä CONTENTS THEO ƒê√öNG ƒê·ªäNH D·∫†NG Y√äU C·∫¶U
                    contents = [image_prompt]
                    if uploaded_ref is not None:
                        # THAY ƒê·ªîI QUAN TR·ªåNG: Ph·∫£i chuy·ªÉn file upload th√†nh ƒë·ªëi t∆∞·ª£ng PIL.Image
                        # ƒê√¢y l√† ƒëi·ªÉm m·∫•u ch·ªët g√¢y l·ªói trong code g·ªëc c·ªßa b·∫°n.
                        ref_image = Image.open(uploaded_ref)
                        contents.append(ref_image)

                    # G·ªåI API V·ªöI ƒê√öNG MODEL V√Ä PH∆Ø∆†NG TH·ª®C TRONG H∆Ø·ªöNG D·∫™N
                    response = client.models.generate_content(
                        model="gemini-2.5-flash-image", # Gi·ªØ nguy√™n t√™n model b·∫°n ƒë√£ cung c·∫•p
                        contents=contents
                    )

                    st.subheader("K·∫øt qu·∫£:")
                    
                    # X·ª¨ L√ù K·∫æT QU·∫¢ TR·∫¢ V·ªÄ ƒê√öNG NH∆Ø H∆Ø·ªöNG D·∫™N
                    # C·∫•u tr√∫c response.parts l√† c·∫•u tr√∫c chu·∫©n
                    image_found = False
                    for part in response.parts:
                        # D·ªØ li·ªáu ·∫£nh n·∫±m trong tr∆∞·ªùng inline_data
                        if part.inline_data:
                            # L·∫•y d·ªØ li·ªáu bytes c·ªßa ·∫£nh
                            image_bytes = part.inline_data.data
                            
                            # Hi·ªÉn th·ªã ·∫£nh l√™n giao di·ªán Streamlit
                            st.image(image_bytes, caption="·∫¢nh do AI t·∫°o ra.", width='content')
                            
                            # Th√™m n√∫t t·∫£i ·∫£nh
                            st.download_button(
                                label="T·∫£i ·∫£nh xu·ªëng",
                                data=image_bytes,
                                file_name="generated_image.png",
                                mime="image/png"
                            )
                            image_found = True
                            break # D·ª´ng l·∫°i sau khi hi·ªÉn th·ªã ·∫£nh ƒë·∫ßu ti√™n

                    if not image_found:
                        st.warning("AI kh√¥ng tr·∫£ v·ªÅ h√¨nh ·∫£nh. Vui l√≤ng th·ª≠ l·∫°i v·ªõi m√¥ t·∫£ kh√°c.")
                        st.code(f"AI Response:\n{response.text}")


                except Exception as e:
                    st.error(f"R·∫•t ti·∫øc, ƒë√£ c√≥ l·ªói x·∫£y ra khi t·∫°o ·∫£nh: {e}")
                    st.error("G·ª£i √Ω: H√£y ƒë·∫£m b·∫£o API Key c·ªßa b·∫°n c√≥ quy·ªÅn truy c·∫≠p model 'gemini-2.5-flash-image' v√† ·∫£nh b·∫°n upload kh√¥ng b·ªã l·ªói.")